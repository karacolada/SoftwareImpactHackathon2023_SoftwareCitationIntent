{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcf74f96-291c-463e-ade7-93a5ddd2e614",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. However note that the system message is optional and the model’s behavior without a system message is likely to be similar to using a generic message such as \"You are a helpful assistant.\"\n",
    "\n",
    "- The user messages provide requests or comments for the assistant to respond to. \n",
    "- Assistant messages store previous assistant responses, but can also be written by you to give examples of desired behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c7bb58b-84e9-45d6-9558-73580835526b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import openai\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, classification_report\n",
    "openai.api_key = \"OPEN_AI_API_KEY\"\n",
    "import warnings\n",
    "import time\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from collections import Counter\n",
    "\n",
    "pred_field = 'sentence' # this can be one of : 'sentence' or 'context'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22470205-e1f5-4d91-97c8-81575cf36713",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sentences = [\"Here, we provide aLFQ, an open-source implementation of algorithms supporting the estimation of protein quantities by any of the aforementioned methods, and additionally provide automated workflows for data analysis and error estimation.\",\n",
    "             \"WGCNA” in R package was used to construct the weighted gene co-expression network [63]\",\n",
    "             \"AccuTyping takes inputs of the two color intensities digitized from scanned microarray images with one of the two popular software packages, GenePix (Axon Instrument, Union City, CA) or ImaGene (Biodiscovery, Inc., El Segundo, CA).\",\n",
    "             \"The survey data were entered into an Access database using a two-pass data verification process and analyzed using SPSS v15.0 software.\",\n",
    "             \"The clinical assessment and laboratory results that were recorded into a Microsoft Access database were analyzed using Statistical Package for the Social Sciences (PASW \\u2013 former SPSS) version 18 and R version 2.9.2 (R Foundation for Statistical Computing, Vienna, Austria).\",\n",
    "             \"4Cin can also generate models using 4C-seq-like data coming from recently developed techniques such as NG Capture-C or Capture-C, as long as they are used to capture at least 4 viewpoints within each region of interest.\",\n",
    "             \"AccuTyping takes inputs of the two color intensities digitized from scanned microarray images with one of the two popular software packages, GenePix (Axon Instrument, Union City, CA) or ImaGene (Biodiscovery, Inc., El Segundo, CA).\",\n",
    "             \"aLFQ was implemented in R as a modular S3 package.\",\n",
    "             \"The 4Cin pipeline can be deployed pulling the docker image from https://hub.docker.com/r/batxes/4cin_ubuntu/ to avoid the installation of the dependencies.\",\n",
    "             \"aLFQ is written in R and freely available under the GPLv3 from CRAN (http://www.cran.r-project.org).\",\n",
    "             \"AlignerBoost is implemented as a uniform Java application and is freely available at https://github.com/Grice-Lab/AlignerBoost.\"]\n",
    "labels = ['creation', 'usage', 'mention', 'usage', 'usage', 'mention', 'mention', 'creation', 'deposition', 'deposition', 'deposition']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34c7f5e0-17f9-4ec2-a1a3-278c2fdb6a67",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65fde911-574c-415c-b189-164c0f8a09b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_data_df = pd.read_csv('../data/software_citation_intent_merged.csv')\n",
    "LABEL2TEXT = {0 : 'creation', 1 : 'usage', 2 : 'mention', 3: 'none'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71a73faf-26af-4318-bbda-21717d9461b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def update_context(df):\n",
    "    df['context'] = df.apply(lambda x: x['context'] if x['context'] == x['context'] else x['sentence'], axis = 1)\n",
    "update_context(final_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bcfdc5b-a683-4c41-bbcc-30cb2ac4d2c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>used</th>\n",
       "      <th>created</th>\n",
       "      <th>mention</th>\n",
       "      <th>context</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PMC5189946</td>\n",
       "      <td>All of this analysis was implemented using Mat...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>All of this analysis was implemented using Mat...</td>\n",
       "      <td>0</td>\n",
       "      <td>All of this analysis was implemented using Mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PMC4511233</td>\n",
       "      <td>Code for calculating partition similarity, obt...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Since the probability of getting a given MI is...</td>\n",
       "      <td>0</td>\n",
       "      <td>Code for calculating partition similarity, obt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PMC4186879</td>\n",
       "      <td>All behavioral statistical analyses were perfo...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>All behavioral statistical analyses were perfo...</td>\n",
       "      <td>2</td>\n",
       "      <td>All behavioral statistical analyses were perfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PMC5026371</td>\n",
       "      <td>M-Track was written using Python 2.7, OpenCV 3...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>M-Track was written using Python 2.7, OpenCV 3...</td>\n",
       "      <td>1</td>\n",
       "      <td>M-Track was written using Python 2.7, OpenCV 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>PMC1283974</td>\n",
       "      <td>Mindboggle is a freely downloadable, open sour...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Mindboggle is a freely downloadable, open sour...</td>\n",
       "      <td>0</td>\n",
       "      <td>Mindboggle is a freely downloadable, open sour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                               text\n",
       "0           0  ...  All of this analysis was implemented using Mat...\n",
       "1           1  ...  Code for calculating partition similarity, obt...\n",
       "2           2  ...  All behavioral statistical analyses were perfo...\n",
       "3           3  ...  M-Track was written using Python 2.7, OpenCV 3...\n",
       "4           4  ...  Mindboggle is a freely downloadable, open sour...\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49bcfeb1-a33a-4921-80c4-9e7b30f73839",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train_df = pd.read_csv('../data/software_citation_intent_train.csv')\n",
    "X_test_df = pd.read_csv('../data/software_citation_intent_test.csv')\n",
    "X_test_df['label_descriptive'] = X_test_df['label'].apply(lambda x: LABEL2TEXT[x])\n",
    "\n",
    "update_context(X_train_df)\n",
    "update_context(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e54177e-ad23-45db-aa71-211cad505dd7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'usage': 449, 'none': 200, 'mention': 95, 'creation': 94})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(X_test_df['label_descriptive'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a244ee08-44aa-4a53-ac47-485ca263d3b4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Zero-shot GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea0d02e1-df40-46ca-a1e9-3acead6a909b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def predict_gpt(sentences, y_test, initial_message, n = -1, print_every = 10, verbose = False):\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    indices = range(len(sentences))\n",
    "    for i, sentence, label in zip(indices[:n], sentences[:n], y_test[:n]):\n",
    "        message = initial_message + [{\"role\": \"user\", \"content\": sentence.strip()}]\n",
    "        try:\n",
    "            completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=message, request_timeout = 10)\n",
    "            predicted_class = completion.choices[0].message.content\n",
    "            if i % print_every == 0:\n",
    "                if not verbose:\n",
    "                    print('Sentence', i)\n",
    "                else:\n",
    "                    print(i, 'Sentence: ', sentence, '\\nPredicted class:', predicted_class, 'Real class:' + label + '\\n\\n')\n",
    "            predicted_labels.append(predicted_class)\n",
    "            true_labels.append(label)\n",
    "        except:\n",
    "            'got an error'\n",
    "            continue\n",
    "    return predicted_labels, true_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59f3e2de-bb2c-4503-8246-f2dee69b3d42",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16aa8337-4656-4b33-b112-c6c80b8ef8a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(true_labels, predicted_labels):\n",
    "    p, r, f1, support = precision_recall_fscore_support(true_labels, predicted_labels, average='macro')\n",
    "    accuracy = round(accuracy_score(true_labels, predicted_labels), 3)\n",
    "    print('Precision: ', round(p, 3), 'Recall: ', round(r, 3), 'F1:', round(f1, 3), 'Accuracy:', accuracy)\n",
    "    print(classification_report(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4c465f9-3bea-4950-baf9-f4a44b762851",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "num_examples = 5\n",
    "examples_used = X_train_df[X_train_df['label_descriptive'] == 'usage'].sample(num_examples)[pred_field].to_list()\n",
    "examples_created = X_train_df[X_train_df['label_descriptive'] == 'creation'].sample(num_examples)[pred_field].to_list()\n",
    "examples_mentioned = X_train_df[X_train_df['label_descriptive'] == 'mention'].sample(num_examples)[pred_field].to_list()\n",
    "examples_none = X_train_df[X_train_df['label_descriptive'] == 'none'].sample(num_examples)['sentence'].to_list()\n",
    "\n",
    "# PROMPT 1\n",
    "initial_message = [{\"role\": \"system\", \n",
    "                \"content\": \"You are a scientist trying to figure out the citation intent behind software mentioned in sentences coming from research articles. Your four categories are: usage, creation, mention, or none. The definitions of the classes are: \\\n",
    "                - usage: software was used in the paper \\\n",
    "                - creation: software was created by the authors of the paper \\\n",
    "                - mention: software was mentioned in the paper, but not used, nor created \\\n",
    "                - none: none of the previous 3 categories apply \\\n",
    "                You need to output one category only.\"}]\n",
    "for example in examples_used:\n",
    "    initial_message += [{\"role\": \"user\", \"content\" : example}]\n",
    "    initial_message += [{\"role\": \"assistant\", \"content\" : 'usage'}]\n",
    "for example in examples_created:\n",
    "    initial_message += [{\"role\": \"user\", \"content\" : example}]\n",
    "    initial_message += [{\"role\": \"assistant\", \"content\" : 'creation'}]\n",
    "for example in examples_mentioned:\n",
    "    initial_message += [{\"role\": \"user\", \"content\" : example}]\n",
    "    initial_message += [{\"role\": \"assistant\", \"content\" : 'mention'}]\n",
    "for example in examples_none:\n",
    "    initial_message += [{\"role\": \"user\", \"content\" : example}]\n",
    "    initial_message += [{\"role\": \"assistant\", \"content\" : 'none'}]\n",
    "\n",
    "# PROMPT 2\n",
    "# initial_message_content = \"You are a scientist trying to figure out the citation intent behind software mentioned in sentences coming from research articles. Your four categories are: usage, creation, mention, or none. The definitions of the classes are: \\\n",
    "#                 - usage: software was used in the paper\"\n",
    "# for example in examples_used:\n",
    "#     initial_message_content += '\\tExample: ' + example\n",
    "# initial_message_content += '- creation: software was created by the authors of the paper'\n",
    "# for example in examples_created:\n",
    "#     initial_message_content += '\\tExample: ' + example\n",
    "# initial_message_content += '- mention: software was mentioned in the paper, but not used, nor created'\n",
    "# for example in examples_created:\n",
    "#     initial_message_content += '\\tExample: ' + example\n",
    "# initial_message_content += \"- none: none of the previous 3 categories apply\"\n",
    "# for example in examples_none:\n",
    "#     initial_message_content += '\\tExample: ' + example\n",
    "\n",
    "# initial_message = [{\"role\": \"system\", \"content\": initial_message_content}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09d41e7b-6e91-4d4e-9de8-78b4e76ffb98",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0b47c41-9f7b-4a25-8395-98599652f946",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "n = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f966f856-a132-4083-88f5-d45b2c29b51f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 3\nSentence 6\nSentence 7\nSentence 8\nSentence 9\nSentence 10\nSentence 11\nSentence 13\nSentence 30\nSentence 33\nSentence 35\nSentence 36\nSentence 37\nSentence 39\nSentence 43\nSentence 44\nSentence 45\nSentence 46\nSentence 47\nSentence 48\nSentence 49\nSentence 50\nSentence 51\nSentence 52\nSentence 53\nSentence 57\nSentence 84\nSentence 85\nSentence 108\nSentence 120\nSentence 122\nSentence 124\nSentence 125\nSentence 140\nSentence 144\nSentence 148\nSentence 149\nSentence 150\nSentence 151\nSentence 153\nSentence 156\nSentence 190\nSentence 194\nSentence 205\nSentence 208\nSentence 221\nSentence 223\nSentence 225\nSentence 234\nSentence 249\nSentence 251\nSentence 254\nSentence 270\nSentence 271\nSentence 272\nSentence 273\nSentence 274\nSentence 284\nSentence 285\nSentence 286\nSentence 287\nSentence 296\nSentence 309\nSentence 312\nSentence 320\nSentence 321\nSentence 331\nSentence 333\nSentence 347\nSentence 350\nSentence 358\nSentence 361\nSentence 363\nSentence 366\nSentence 373\nSentence 382\nSentence 384\nSentence 387\nSentence 388\nSentence 389\nSentence 391\nSentence 394\nSentence 401\nSentence 404\nSentence 410\nSentence 413\nSentence 416\nSentence 417\nSentence 418\nSentence 419\nSentence 420\nSentence 421\nSentence 427\nSentence 431\nSentence 437\nSentence 439\nSentence 443\nSentence 444\nSentence 468\nSentence 480\nSentence 482\nSentence 484\nSentence 489\nSentence 512\nSentence 513\nSentence 514\nSentence 515\nSentence 516\nSentence 517\nSentence 518\nSentence 525\nSentence 528\nSentence 531\nSentence 532\nSentence 535\nSentence 537\nSentence 540\nSentence 541\nSentence 542\nSentence 543\nSentence 554\nSentence 556\nSentence 558\nSentence 560\nSentence 566\nSentence 589\nSentence 591\nSentence 592\nSentence 597\nSentence 598\nSentence 600\nSentence 602\nSentence 605\nSentence 608\nSentence 609\nSentence 610\nSentence 611\nSentence 612\nSentence 613\nSentence 614\nSentence 615\nSentence 616\nSentence 617\nSentence 618\nSentence 619\nSentence 620\nSentence 621\nSentence 622\nSentence 623\nSentence 624\nSentence 625\nSentence 626\nSentence 627\nSentence 630\nSentence 631\nSentence 632\nSentence 635\nSentence 637\nSentence 640\nSentence 641\nSentence 642\nSentence 643\nSentence 644\nSentence 645\nSentence 646\nSentence 647\nSentence 648\nSentence 649\nSentence 650\nSentence 652\nSentence 653\nSentence 654\nSentence 655\nSentence 656\nSentence 657\nSentence 658\nSentence 659\nSentence 660\nSentence 661\nSentence 662\nSentence 663\nSentence 664\nSentence 665\nSentence 666\nSentence 667\nSentence 668\nSentence 669\nSentence 670\nSentence 671\nSentence 672\nSentence 673\nSentence 674\nSentence 675\nSentence 676\nSentence 677\nSentence 691\nSentence 701\nSentence 709\nSentence 718\nSentence 743\nSentence 746\nSentence 749\nSentence 751\nSentence 752\nSentence 755\nSentence 758\nSentence 760\nSentence 789\nSentence 793\nSentence 794\nSentence 800\nSentence 802\nSentence 805\nSentence 808\nSentence 809\nSentence 811\nSentence 812\nSentence 813\nSentence 814\nSentence 815\nSentence 816\nSentence 817\nSentence 818\nSentence 819\nSentence 820\nSentence 821\nSentence 822\nSentence 823\nSentence 824\nSentence 825\nSentence 826\nSentence 827\nSentence 828\nSentence 829\nSentence 830\nSentence 831\nSentence 832\nSentence 834\nSentence 835\nSentence 836\n"
     ]
    }
   ],
   "source": [
    "test_sentences = X_test_df[pred_field].to_list()\n",
    "y_test = X_test_df['label_descriptive'].to_list()\n",
    "y_pred, y_test_completed = predict_gpt(test_sentences, y_test, initial_message, n = n, print_every = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c64d2bca-256c-4af4-890a-8f870488addf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.667 Recall:  0.469 F1: 0.45 Accuracy: 0.517\n              precision    recall  f1-score   support\n\n    creation       1.00      0.25      0.40        20\n     mention       0.33      0.29      0.31        24\n        none       0.40      0.97      0.56        67\n       usage       0.94      0.36      0.53       129\n\n    accuracy                           0.52       240\n   macro avg       0.67      0.47      0.45       240\nweighted avg       0.73      0.52      0.50       240\n\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test_completed, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3618c25-1aa6-4045-8fc5-e4f5dbe1951f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### CZI validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af28df2d-9d8f-45d7-9443-34b3d4670ae3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0\nSentence 1\nSentence 2\nSentence 3\nSentence 4\nSentence 6\nSentence 7\nSentence 8\nSentence 9\nSentence 11\nSentence 12\nSentence 13\nSentence 14\nSentence 15\nSentence 16\nSentence 17\nSentence 18\nSentence 20\nSentence 21\nSentence 22\nSentence 23\nSentence 24\nSentence 25\nSentence 26\nSentence 27\nSentence 28\nSentence 29\nSentence 30\nSentence 31\nSentence 32\nSentence 33\nSentence 34\nSentence 35\nSentence 36\nSentence 37\nSentence 38\nSentence 39\nSentence 40\nSentence 41\nSentence 42\nSentence 44\nSentence 45\nSentence 46\nSentence 47\nSentence 48\nSentence 49\nSentence 50\nSentence 51\nSentence 52\nSentence 53\nSentence 54\nSentence 55\nSentence 56\nSentence 57\nSentence 58\nSentence 59\nSentence 60\nSentence 61\nSentence 62\nSentence 63\nSentence 64\nSentence 65\nSentence 67\nSentence 68\nSentence 69\nSentence 70\nSentence 71\nSentence 72\nSentence 73\nSentence 74\nSentence 75\nSentence 77\nSentence 78\nSentence 79\nSentence 80\nSentence 81\nSentence 82\nSentence 83\nSentence 84\nSentence 85\nSentence 86\nSentence 87\nSentence 88\nSentence 89\nSentence 90\nSentence 91\nSentence 92\nSentence 93\nSentence 94\nSentence 95\nSentence 96\nSentence 97\nSentence 98\nSentence 99\nSentence 100\nSentence 101\nSentence 102\nSentence 103\nSentence 104\nSentence 105\nSentence 106\nSentence 107\nSentence 108\nSentence 109\nSentence 110\nSentence 111\nSentence 112\nSentence 113\nSentence 114\nSentence 115\nSentence 116\nSentence 117\nSentence 118\nSentence 119\nSentence 120\nSentence 121\nSentence 122\nSentence 123\nSentence 124\nSentence 125\nSentence 126\nSentence 127\nSentence 128\nSentence 129\nSentence 130\nSentence 131\nSentence 132\nSentence 133\nSentence 134\nSentence 135\nSentence 136\nSentence 137\nSentence 138\nSentence 139\nSentence 140\nSentence 141\nSentence 142\nSentence 143\nSentence 144\nSentence 145\nSentence 146\nSentence 147\nSentence 148\nSentence 149\nSentence 150\nSentence 151\nSentence 152\nSentence 153\nSentence 154\nSentence 155\nSentence 156\nSentence 157\nSentence 158\nSentence 159\nSentence 160\nSentence 161\nSentence 162\nSentence 163\nSentence 164\nSentence 166\nSentence 167\nSentence 168\nSentence 169\nSentence 170\nSentence 171\nSentence 172\nSentence 173\nSentence 174\nSentence 175\nSentence 176\nSentence 177\nSentence 178\nSentence 179\nSentence 180\nSentence 181\nSentence 182\nSentence 183\nSentence 184\nSentence 185\nSentence 186\nSentence 187\nSentence 188\nSentence 189\nSentence 190\nSentence 191\nSentence 193\nSentence 194\nSentence 195\nSentence 196\nSentence 197\nSentence 198\nSentence 199\nSentence 200\nSentence 201\nSentence 202\nSentence 203\nSentence 204\nSentence 205\nSentence 206\nSentence 207\nSentence 208\nSentence 210\nSentence 211\nSentence 212\nSentence 213\nSentence 214\nSentence 215\nSentence 216\nSentence 217\nSentence 218\nSentence 219\nSentence 220\nSentence 221\nSentence 222\nSentence 223\nSentence 224\nSentence 225\nSentence 226\nSentence 227\nSentence 228\nSentence 229\nSentence 230\nSentence 231\nSentence 232\nSentence 233\nSentence 234\nSentence 235\nSentence 236\nSentence 237\nSentence 238\nSentence 239\nSentence 240\nSentence 241\nSentence 242\nSentence 243\nSentence 244\nSentence 245\nSentence 246\nSentence 247\nSentence 248\nSentence 249\nSentence 250\nSentence 251\nSentence 252\nSentence 254\nSentence 255\nSentence 256\nSentence 257\nSentence 258\nSentence 260\nSentence 263\nSentence 264\nSentence 265\nSentence 266\nSentence 267\nSentence 268\nSentence 269\nSentence 270\nSentence 271\nSentence 272\nSentence 273\nSentence 274\nSentence 275\nSentence 276\nSentence 278\nSentence 279\nSentence 280\nSentence 281\nSentence 283\nSentence 284\nSentence 285\nSentence 286\nSentence 287\nSentence 288\nSentence 289\nSentence 290\nSentence 291\nSentence 292\nSentence 293\nSentence 294\nSentence 295\nSentence 296\nSentence 297\nSentence 298\nSentence 299\nSentence 300\nSentence 301\nSentence 302\nSentence 303\nSentence 304\nSentence 306\nSentence 307\nSentence 308\nSentence 309\nSentence 310\nSentence 311\nSentence 312\nSentence 313\nSentence 314\nSentence 315\nSentence 316\nSentence 317\nSentence 318\nSentence 319\nSentence 320\nSentence 322\nSentence 323\nSentence 324\nSentence 326\nSentence 327\nSentence 328\nSentence 329\nSentence 330\nSentence 331\nSentence 332\nSentence 333\nSentence 334\nSentence 335\nSentence 336\nSentence 337\nSentence 338\nSentence 339\nSentence 340\nSentence 341\nSentence 342\nSentence 343\nSentence 345\nSentence 346\nSentence 347\nSentence 348\nSentence 349\nSentence 350\nSentence 351\nSentence 352\nSentence 353\nSentence 354\nSentence 355\nSentence 356\nSentence 357\nSentence 358\nSentence 359\nSentence 360\nSentence 361\nSentence 362\nSentence 363\nSentence 364\nSentence 365\nSentence 366\nSentence 367\nSentence 368\nSentence 369\nSentence 370\nSentence 371\nSentence 372\nSentence 373\nSentence 374\nSentence 375\nSentence 376\nSentence 377\nSentence 378\nSentence 379\nSentence 380\nSentence 381\nSentence 382\nSentence 383\nSentence 384\nSentence 385\nSentence 386\nSentence 387\nSentence 388\nSentence 389\nSentence 390\nSentence 391\nSentence 392\nSentence 393\nSentence 394\nSentence 395\nSentence 396\nSentence 397\nSentence 398\nSentence 400\nSentence 401\nSentence 402\nSentence 403\nSentence 404\nSentence 405\nSentence 406\nSentence 407\nSentence 408\n"
     ]
    }
   ],
   "source": [
    "czi_combined = pd.read_csv('/Workspace/Users/aistrate@chanzuckerberg.com/czi_val.csv')\n",
    "test_sentences_czi = czi_combined['text'].to_list()\n",
    "y_test_czi = czi_combined['label'].to_list()\n",
    "y_pred_czi, y_test_czi_completed = predict_gpt(test_sentences_czi, y_test_czi, initial_message, n = n, print_every = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a38cbf1-c7b1-49ee-86bc-50f2ee4f74bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.429 Recall:  0.378 F1: 0.29 Accuracy: 0.332\n              precision    recall  f1-score   support\n\n    creation       0.50      0.33      0.40         9\n     mention       0.17      0.19      0.18        27\n        none       0.05      0.67      0.09        18\n       usage       1.00      0.33      0.49       335\n\n    accuracy                           0.33       389\n   macro avg       0.43      0.38      0.29       389\nweighted avg       0.89      0.33      0.45       389\n\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test_czi_completed, y_pred_czi)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "gpt_few_shot_sentence_instr",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
