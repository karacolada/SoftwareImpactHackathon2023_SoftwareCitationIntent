{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1b23857-5e2d-4e64-83d6-2f5966744296",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Requirement already satisfied: torch in /databricks/python3/lib/python3.10/site-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: transformers in /databricks/python3/lib/python3.10/site-packages (4.31.0)\n",
      "Requirement already satisfied: optuna in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages (3.4.0)\n",
      "Requirement already satisfied: seaborn in /databricks/python3/lib/python3.10/site-packages (0.12.2)\n",
      "Requirement already satisfied: torchmetrics in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages (1.2.0)\n",
      "Collecting iterative-stratification\n",
      "  Downloading iterative_stratification-0.1.7-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: filelock in /databricks/python3/lib/python3.10/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: sympy in /databricks/python3/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions in /databricks/python3/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: networkx in /databricks/python3/lib/python3.10/site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /databricks/python3/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: lit in /databricks/python3/lib/python3.10/site-packages (from triton==2.0.0->torch) (17.0.2)\n",
      "Requirement already satisfied: cmake in /databricks/python3/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.27.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /databricks/python3/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: requests in /databricks/python3/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.10/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /databricks/python3/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /databricks/python3/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /databricks/python3/lib/python3.10/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /databricks/python3/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages (from optuna) (1.12.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /databricks/python3/lib/python3.10/site-packages (from optuna) (1.4.39)\n",
      "Requirement already satisfied: colorlog in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: pandas>=0.25 in /databricks/python3/lib/python3.10/site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /databricks/python3/lib/python3.10/site-packages (from seaborn) (3.7.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages (from torchmetrics) (0.9.0)\n",
      "Requirement already satisfied: scikit-learn in /databricks/python3/lib/python3.10/site-packages (from iterative-stratification) (1.1.1)\n",
      "Requirement already satisfied: scipy in /databricks/python3/lib/python3.10/site-packages (from iterative-stratification) (1.10.0)\n",
      "Requirement already satisfied: Mako in /databricks/python3/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.2.0)\n",
      "Requirement already satisfied: fsspec in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2022.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas>=0.25->seaborn) (2022.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn->iterative-stratification) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn->iterative-stratification) (1.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /databricks/python3/lib/python3.10/site-packages (from sympy->torch) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Installing collected packages: iterative-stratification\n",
      "Successfully installed iterative-stratification-0.1.7\n",
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install torch transformers optuna seaborn torchmetrics iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f6cfb5c-4e7d-4f15-931b-2f1ba676d948",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, f1_score, accuracy_score\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import json\n",
    "import optuna\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel, AutoModel\n",
    "from torchmetrics.classification import MultilabelHammingDistance\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "# from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdeed3e2-7d95-492c-aa23-ff207fa804d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# DATA_FPATH = '/dbfs/FileStore/citation_intent/software_intent_data___final_data.csv'\n",
    "DATA_FPATH = '/dbfs/FileStore/citation_intent/final_df_w_unlabeled.csv'\n",
    "OUTPUT_PATH = '/dbfs/FileStore/citation_intent/'\n",
    "\n",
    "df = pd.read_csv(DATA_FPATH, index_col=None)\n",
    "# df = df.drop(['Unnamed: 6'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b132b86-2992-442d-a365-0d225b66f284",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>used</th>\n",
       "      <th>created</th>\n",
       "      <th>mention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PMC5189946</td>\n",
       "      <td>All of this analysis was implemented using Mat...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PMC4511233</td>\n",
       "      <td>Code for calculating partition similarity, obt...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PMC4186879</td>\n",
       "      <td>All behavioral statistical analyses were perfo...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PMC5026371</td>\n",
       "      <td>M-Track was written using Python 2.7, OpenCV 3...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PMC1283974</td>\n",
       "      <td>Mindboggle is a freely downloadable, open sour...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4212</th>\n",
       "      <td>PMC3579796</td>\n",
       "      <td>To that end, each hen was gently maintained ap...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>PMC4701393</td>\n",
       "      <td>Immediately before the odor is presented, the ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4214</th>\n",
       "      <td>PMC4153588</td>\n",
       "      <td>Samples were collected seven times on an ordin...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215</th>\n",
       "      <td>PMC4701393</td>\n",
       "      <td>This scale consists of six verbal and five per...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4216</th>\n",
       "      <td>PMC7305855</td>\n",
       "      <td>Erlotinib is a tyrosine kinase inhibitor of EG...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4217 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  ... mention\n",
       "0     PMC5189946  ...   False\n",
       "1     PMC4511233  ...   False\n",
       "2     PMC4186879  ...    True\n",
       "3     PMC5026371  ...   False\n",
       "4     PMC1283974  ...   False\n",
       "...          ...  ...     ...\n",
       "4212  PMC3579796  ...   False\n",
       "4213  PMC4701393  ...   False\n",
       "4214  PMC4153588  ...   False\n",
       "4215  PMC4701393  ...   False\n",
       "4216  PMC7305855  ...   False\n",
       "\n",
       "[4217 rows x 5 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fa419df-8f6d-4b3b-8d06-f1ae415142be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df['used'] = df['used'].replace(True, 'used')\n",
    "df['created'] = df['created'].replace(True, 'created')\n",
    "df['mention'] = df['mention'].replace(True, 'mention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3dec316-84d1-48d8-8d0f-95e8e20fa444",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df['label'] = df[['used', 'created', 'mention']].values.tolist()\n",
    "df['label'] = df['label'].apply(lambda x: [i for i in x if i])\n",
    "df['label'] = df['label'].apply(lambda x: x if len(x)>0 else ['unlabeled'])\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4846231-eb39-4aef-b7c9-50ba28c7e996",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>used</th>\n",
       "      <th>created</th>\n",
       "      <th>mention</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PMC5189946</td>\n",
       "      <td>All of this analysis was implemented using Mat...</td>\n",
       "      <td>False</td>\n",
       "      <td>created</td>\n",
       "      <td>False</td>\n",
       "      <td>[created]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PMC4511233</td>\n",
       "      <td>Code for calculating partition similarity, obt...</td>\n",
       "      <td>False</td>\n",
       "      <td>created</td>\n",
       "      <td>False</td>\n",
       "      <td>[created]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PMC4186879</td>\n",
       "      <td>All behavioral statistical analyses were perfo...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>mention</td>\n",
       "      <td>[mention]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PMC5026371</td>\n",
       "      <td>M-Track was written using Python 2.7, OpenCV 3...</td>\n",
       "      <td>used</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[used]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>PMC1283974</td>\n",
       "      <td>Mindboggle is a freely downloadable, open sour...</td>\n",
       "      <td>False</td>\n",
       "      <td>created</td>\n",
       "      <td>False</td>\n",
       "      <td>[created]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4212</th>\n",
       "      <td>4212</td>\n",
       "      <td>PMC3579796</td>\n",
       "      <td>To that end, each hen was gently maintained ap...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[unlabeled]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>4213</td>\n",
       "      <td>PMC4701393</td>\n",
       "      <td>Immediately before the odor is presented, the ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[unlabeled]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4214</th>\n",
       "      <td>4214</td>\n",
       "      <td>PMC4153588</td>\n",
       "      <td>Samples were collected seven times on an ordin...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[unlabeled]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215</th>\n",
       "      <td>4215</td>\n",
       "      <td>PMC4701393</td>\n",
       "      <td>This scale consists of six verbal and five per...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[unlabeled]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4216</th>\n",
       "      <td>4216</td>\n",
       "      <td>PMC7305855</td>\n",
       "      <td>Erlotinib is a tyrosine kinase inhibitor of EG...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[unlabeled]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4217 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index          id  ...  mention        label\n",
       "0         0  PMC5189946  ...    False    [created]\n",
       "1         1  PMC4511233  ...    False    [created]\n",
       "2         2  PMC4186879  ...  mention    [mention]\n",
       "3         3  PMC5026371  ...    False       [used]\n",
       "4         4  PMC1283974  ...    False    [created]\n",
       "...     ...         ...  ...      ...          ...\n",
       "4212   4212  PMC3579796  ...    False  [unlabeled]\n",
       "4213   4213  PMC4701393  ...    False  [unlabeled]\n",
       "4214   4214  PMC4153588  ...    False  [unlabeled]\n",
       "4215   4215  PMC4701393  ...    False  [unlabeled]\n",
       "4216   4216  PMC7305855  ...    False  [unlabeled]\n",
       "\n",
       "[4217 rows x 7 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7c87959-ce43-47f9-81a9-71fc0b48323e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df['word_count'] = df['sentence'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b380724-0773-43c4-9df8-79099fb2f1be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'word_count'}>]], dtype=object)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist('word_count', bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61587126-55bf-4ef7-ad66-279fb9c9d059",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CLASSES = ['Created', 'Used', 'Mention']\n",
    "CLASSES = ['used', 'created', 'mention', 'unlabeled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fdc6687-bee0-4812-a0a3-933a54c5c274",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def vectorize_labels(df_y):\n",
    "    \"\"\"\n",
    "    Transform labels into one-hot encoded vector representation\n",
    "    \"\"\"\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    vectorized_y = mlb.fit_transform(df_y)\n",
    "\n",
    "    return mlb, vectorized_y\n",
    "\n",
    "mlb, vectorized_labels = vectorize_labels(df['label'])\n",
    "\n",
    "df['vectorized_labels'] = vectorized_labels.tolist()\n",
    "\n",
    "with open(f\"{OUTPUT_PATH}/multilabel_binarizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mlb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07d2e798-988e-4052-bcd6-a6855d66b0d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df[~df['label'].apply(lambda x: len(x)>1)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36940c96-8c51-43a0-be09-9c0edb64a35d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explode_df = df.explode('label')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.suptitle(\"Distribution of Labels in Data\", fontsize=16)\n",
    "countplot = sns.countplot(data=explode_df, x=\"label\")\n",
    "countplot.set_xticklabels(countplot.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1161d757-4a80-46ac-9002-42ca70b1cc2a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class SoftwareDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset class that inherits from torch.utils.data.Dataset\n",
    "\n",
    "    Makes use of Hugging Face transformer encode_plus method to:\n",
    "        -Split sentence into tokens\n",
    "        -Add special [CLS] and [SEP] tokens\n",
    "        -Map tokens to IDs\n",
    "        -Pad/truncate sentences to max length\n",
    "        -Create attention masks\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    dataframe: pd.DataFrame used for model training, contains columns 'text' and vectorized labels 'target_list'\n",
    "    tokenizer: tokenizer from transformers library used to prepare inputs for model\n",
    "    max_len: maximum length (in number of tokens) for the inputs to model\n",
    "\n",
    "    Returns\n",
    "    _______\n",
    "\n",
    "    dict: Dictionary of encoded ids, mask, token_type_ids, and targets\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataframe, max_len):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "        self.data = dataframe\n",
    "        self.text = self.data.sentence\n",
    "        self.targets = self.data.vectorized_labels\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self): # overrides __len__ so that len(dataset) returns size of dataset\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index): #override __getitem__ to support indexing\n",
    "        text = str(self.text[index])\n",
    "        text = ' '.join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens = True,\n",
    "            max_length = self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids = True,\n",
    "            truncation = True\n",
    "        )\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs['token_type_ids']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c787e8cc-bdef-48d7-8a86-aa718025d8bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (4215, 10)\n",
      "TRAIN Dataset: (3372, 10)\n",
      "TEST Dataset: (843, 10)\n"
     ]
    }
   ],
   "source": [
    "def split_data(df, test_size):\n",
    "    \"\"\"\n",
    "    Utility function to create train and validation datasets using stratified\n",
    "    shuffling for multi-label data via iterstrat package\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    df: pd.DataFrame that contains modeling data\n",
    "    test_size: float that designates proportion of data used for testing\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_dataset: pd.DataFrame that contains training samples\n",
    "    valid_dataset: pd.DataFrame that contains validation samples\n",
    "    \"\"\"  \n",
    "\n",
    "    x = df['sentence'].tolist()\n",
    "    y= df['vectorized_labels'].tolist()\n",
    "    sss = StratifiedShuffleSplit(n_splits=2, test_size=test_size, random_state=18)\n",
    "    for train_index, valid_index in sss.split(x, y):\n",
    "        train_dataset, valid_dataset = df.loc[train_index].reset_index(drop=True), df.loc[valid_index].reset_index(drop=True)\n",
    "        \n",
    "    print(\"FULL Dataset: {}\".format(df.shape))\n",
    "    print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "    print(\"TEST Dataset: {}\".format(valid_dataset.shape))\n",
    "\n",
    "    return train_dataset, valid_dataset\n",
    "train_dataset, valid_dataset = split_data(df, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce5893a4-0118-4238-b045-7e07166b9240",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 20:33:31,941] A new study created in memory with name: no-name-209c769b-48e7-4765-a203-8288c4e3de36\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamw.AdamW'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.6132689714431763\n",
      "Validation Loss: 1.4168911730801617\n",
      "Validation loss decreased (inf --> 1.416891).\n",
      "Epoch: 2, batch_id: 0, Training Loss:  1.5950239896774292\n",
      "Validation Loss: 1.4248560446280019\n",
      "Epoch: 3, batch_id: 0, Training Loss:  1.2150306701660156\n",
      "Validation Loss: 1.4050713424329409\n",
      "Validation loss decreased (1.416891 --> 1.405071).\n",
      "Epoch: 4, batch_id: 0, Training Loss:  1.356712818145752\n",
      "Validation Loss: 1.1314857867028978\n",
      "Validation loss decreased (1.405071 --> 1.131486).\n",
      "Epoch: 5, batch_id: 0, Training Loss:  1.1817259788513184\n",
      "Validation Loss: 1.075026660053818\n",
      "Validation loss decreased (1.131486 --> 1.075027).\n",
      "Epoch: 6, batch_id: 0, Training Loss:  0.9767861366271973\n",
      "Validation Loss: 1.0008502624653002\n",
      "Validation loss decreased (1.075027 --> 1.000850).\n",
      "Epoch: 7, batch_id: 0, Training Loss:  0.8145021796226501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 20:36:05,440] Trial 0 finished with value: 0.4653347016166707 and parameters: {'max_len': 128, 'batch_size': 32, 'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.00036222532337013317, 'weight_decay': 0.0075038335979611855, 'n_epochs': 7, 'pred_threshold': 0.31460135807652984, 'pos_weight': (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147), 'dropout': 0.07581254502308872}. Best is trial 0 with value: 0.4653347016166707.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.9980814214105956\n",
      "Validation loss decreased (1.000850 --> 0.998081).\n",
      "F1 Score (Macro) = 0.4653347016166707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamw.AdamW'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.479135274887085\n",
      "Validation Loss: 0.4002435290151172\n",
      "Validation loss decreased (inf --> 0.400244).\n",
      "Epoch: 2, batch_id: 0, Training Loss:  0.3497631251811981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 20:36:50,129] Trial 1 finished with value: 0.6249397994586924 and parameters: {'max_len': 128, 'batch_size': 32, 'optimizer': <class 'torch.optim.adamw.AdamW'>, 'lr': 0.0001809416848925797, 'weight_decay': 0.03551265172957261, 'n_epochs': 2, 'pred_threshold': 0.34126523367586364, 'pos_weight': None, 'dropout': 0.4266823216880847}. Best is trial 1 with value: 0.6249397994586924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5458982879364931\n",
      "F1 Score (Macro) = 0.6249397994586924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamw.AdamW'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.6772677898406982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 20:37:12,000] Trial 2 finished with value: 0.6792878412097612 and parameters: {'max_len': 128, 'batch_size': 64, 'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.0003028833396233714, 'weight_decay': 0.09546416710928335, 'n_epochs': 1, 'pred_threshold': 0.5815652109618797, 'pos_weight': (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147), 'dropout': 0.5512668159023625}. Best is trial 2 with value: 0.6792878412097612.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5048239114029066\n",
      "Validation loss decreased (inf --> 0.504824).\n",
      "F1 Score (Macro) = 0.6792878412097612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamw.AdamW'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.6114212274551392\n",
      "Validation Loss: 1.3860180377960205\n",
      "Validation loss decreased (inf --> 1.386018).\n",
      "Epoch: 2, batch_id: 0, Training Loss:  1.6844890117645264\n",
      "Validation Loss: 1.40025077925788\n",
      "Epoch: 3, batch_id: 0, Training Loss:  1.2502589225769043\n",
      "Validation Loss: 1.4147894426628398\n",
      "Epoch: 4, batch_id: 0, Training Loss:  1.4857202768325806\n",
      "Validation Loss: 1.4131780686201871\n",
      "Epoch: 5, batch_id: 0, Training Loss:  1.5386903285980225\n",
      "Validation Loss: 1.3944736410070349\n",
      "Epoch: 6, batch_id: 0, Training Loss:  1.3661231994628906\n",
      "Validation Loss: 1.38681408211037\n",
      "Epoch: 7, batch_id: 0, Training Loss:  1.3111622333526611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 20:39:46,582] Trial 3 finished with value: 0.0 and parameters: {'max_len': 128, 'batch_size': 32, 'optimizer': <class 'torch.optim.adamw.AdamW'>, 'lr': 0.00021818573279306334, 'weight_decay': 0.09162482240911775, 'n_epochs': 7, 'pred_threshold': 0.5846133334950772, 'pos_weight': (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147), 'dropout': 0.32871961132734484}. Best is trial 2 with value: 0.6792878412097612.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.39400550171181\n",
      "F1 Score (Macro) = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamw.AdamW'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.5001180171966553\n",
      "Validation Loss: 0.30871747540576117\n",
      "Validation loss decreased (inf --> 0.308717).\n",
      "Epoch: 2, batch_id: 0, Training Loss:  0.2504061758518219\n",
      "Validation Loss: 0.32403476642710827\n",
      "Epoch: 3, batch_id: 0, Training Loss:  0.2530062198638916\n",
      "Validation Loss: 0.2989611226533141\n",
      "Validation loss decreased (0.308717 --> 0.298961).\n",
      "Epoch: 4, batch_id: 0, Training Loss:  0.058400385081768036\n",
      "Validation Loss: 0.36820670110838755\n",
      "Epoch: 5, batch_id: 0, Training Loss:  0.05679966136813164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 20:41:31,583] Trial 4 finished with value: 0.833539184945753 and parameters: {'max_len': 128, 'batch_size': 64, 'optimizer': <class 'torch.optim.adamw.AdamW'>, 'lr': 7.404316140057675e-05, 'weight_decay': 0.07071222065173641, 'n_epochs': 5, 'pred_threshold': 0.44824046711325005, 'pos_weight': (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147), 'dropout': 0.019855535131188807}. Best is trial 4 with value: 0.833539184945753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.41673695828233454\n",
      "F1 Score (Macro) = 0.833539184945753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamw.AdamW'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.3935084342956543\n",
      "Validation Loss: 0.35462136885949547\n",
      "Validation loss decreased (inf --> 0.354621).\n",
      "Epoch: 2, batch_id: 0, Training Loss:  0.36714115738868713\n",
      "Validation Loss: 0.25848974181073053\n",
      "Validation loss decreased (0.354621 --> 0.258490).\n",
      "Epoch: 3, batch_id: 0, Training Loss:  0.10285471379756927\n",
      "Validation Loss: 0.24904721230268478\n",
      "Validation loss decreased (0.258490 --> 0.249047).\n",
      "Epoch: 4, batch_id: 0, Training Loss:  0.06117868423461914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 20:42:55,785] Trial 5 finished with value: 0.8165413782630108 and parameters: {'max_len': 128, 'batch_size': 64, 'optimizer': <class 'torch.optim.adamw.AdamW'>, 'lr': 2.6293770276773504e-05, 'weight_decay': 0.06394833602116515, 'n_epochs': 4, 'pred_threshold': 0.46294808736437393, 'pos_weight': None, 'dropout': 0.0005042905255400187}. Best is trial 4 with value: 0.833539184945753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2512338273227215\n",
      "F1 Score (Macro) = 0.8165413782630108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamw.AdamW'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.462436318397522\n",
      "Validation Loss: 0.5411401582615716\n",
      "Validation loss decreased (inf --> 0.541140).\n",
      "Epoch: 2, batch_id: 0, Training Loss:  0.5731735229492188\n",
      "Validation Loss: 0.34392042351620544\n",
      "Validation loss decreased (0.541140 --> 0.343920).\n",
      "Epoch: 3, batch_id: 0, Training Loss:  0.22076410055160522\n",
      "Validation Loss: 0.35378111260277884\n",
      "Epoch: 4, batch_id: 0, Training Loss:  0.11449871212244034\n",
      "Validation Loss: 0.3042416641754764\n",
      "Validation loss decreased (0.343920 --> 0.304242).\n",
      "Epoch: 5, batch_id: 0, Training Loss:  0.10985636711120605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 20:44:40,872] Trial 6 finished with value: 0.7508023737484826 and parameters: {'max_len': 128, 'batch_size': 64, 'optimizer': <class 'torch.optim.adamw.AdamW'>, 'lr': 1.136133965023574e-05, 'weight_decay': 0.06190458734400411, 'n_epochs': 5, 'pred_threshold': 0.43282562605667785, 'pos_weight': (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147), 'dropout': 0.1550713652279333}. Best is trial 4 with value: 0.833539184945753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.28963212562458857\n",
      "Validation loss decreased (0.304242 --> 0.289632).\n",
      "F1 Score (Macro) = 0.7508023737484826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamw.AdamW'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.6322269439697266\n",
      "Validation Loss: 0.3928094346608434\n",
      "Validation loss decreased (inf --> 0.392809).\n",
      "Epoch: 2, batch_id: 0, Training Loss:  0.3400396704673767\n",
      "Validation Loss: 0.36850238697869436\n",
      "Validation loss decreased (0.392809 --> 0.368502).\n",
      "Epoch: 3, batch_id: 0, Training Loss:  0.13334152102470398\n",
      "Validation Loss: 0.3406139463186264\n",
      "Validation loss decreased (0.368502 --> 0.340614).\n",
      "Epoch: 4, batch_id: 0, Training Loss:  0.08530363440513611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 20:46:05,371] Trial 7 finished with value: 0.7913821791064926 and parameters: {'max_len': 128, 'batch_size': 64, 'optimizer': <class 'torch.optim.adamw.AdamW'>, 'lr': 0.00011343584590414957, 'weight_decay': 0.07606988616438036, 'n_epochs': 4, 'pred_threshold': 0.4576432364984283, 'pos_weight': (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147), 'dropout': 0.20111420795968948}. Best is trial 4 with value: 0.833539184945753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.366439693740436\n",
      "F1 Score (Macro) = 0.7913821791064926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamw.AdamW'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.4146802425384521\n",
      "Validation Loss: 0.31219931053263794\n",
      "Validation loss decreased (inf --> 0.312199).\n",
      "Epoch: 2, batch_id: 0, Training Loss:  0.3026081621646881\n",
      "Validation Loss: 0.32725270411797935\n",
      "Epoch: 3, batch_id: 0, Training Loss:  0.16742423176765442\n",
      "Validation Loss: 0.33161068175520214\n",
      "Epoch: 4, batch_id: 0, Training Loss:  0.19575166702270508\n",
      "Validation Loss: 0.3259335224117551\n",
      "Epoch: 5, batch_id: 0, Training Loss:  0.20187048614025116\n",
      "Validation Loss: 0.43358932009765083\n",
      "Epoch: 6, batch_id: 0, Training Loss:  0.30418962240219116\n",
      "Validation Loss: 0.3323793826358659\n",
      "Epoch: 7, batch_id: 0, Training Loss:  0.2707141041755676\n",
      "Validation Loss: 0.38393164638962063\n",
      "Epoch: 8, batch_id: 0, Training Loss:  0.2609424293041229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 20:48:52,568] Trial 8 finished with value: 0.6963138987934957 and parameters: {'max_len': 128, 'batch_size': 64, 'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 9.863009168830766e-05, 'weight_decay': 0.03971794426456192, 'n_epochs': 8, 'pred_threshold': 0.39879768980251873, 'pos_weight': None, 'dropout': 0.0003584440927244456}. Best is trial 4 with value: 0.833539184945753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.47406129432576044\n",
      "F1 Score (Macro) = 0.6963138987934957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamw.AdamW'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.5482752323150635\n",
      "Validation Loss: 0.4474468252488545\n",
      "Validation loss decreased (inf --> 0.447447).\n",
      "Epoch: 2, batch_id: 0, Training Loss:  0.4621189534664154\n",
      "Validation Loss: 0.38125168638569973\n",
      "Validation loss decreased (0.447447 --> 0.381252).\n",
      "Epoch: 3, batch_id: 0, Training Loss:  0.184409961104393\n",
      "Validation Loss: 0.3236986882984639\n",
      "Validation loss decreased (0.381252 --> 0.323699).\n",
      "Epoch: 4, batch_id: 0, Training Loss:  0.09350299835205078\n",
      "Validation Loss: 0.3850560794983591\n",
      "Epoch: 5, batch_id: 0, Training Loss:  0.12960770726203918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 20:50:37,652] Trial 9 finished with value: 0.72397660561843 and parameters: {'max_len': 128, 'batch_size': 64, 'optimizer': <class 'torch.optim.adamw.AdamW'>, 'lr': 0.00011322870736596475, 'weight_decay': 0.07443163298340727, 'n_epochs': 5, 'pred_threshold': 0.4779792731610181, 'pos_weight': (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147), 'dropout': 0.2327827167599796}. Best is trial 4 with value: 0.833539184945753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.38761932935033533\n",
      "F1 Score (Macro) = 0.72397660561843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamw.AdamW'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.3578813076019287\n",
      "Validation Loss: 0.648963777003465\n",
      "Validation loss decreased (inf --> 0.648964).\n",
      "Epoch: 2, batch_id: 0, Training Loss:  0.7609120011329651\n",
      "Validation Loss: 0.7482583147508126\n",
      "Epoch: 3, batch_id: 0, Training Loss:  0.4176456928253174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 20:51:44,654] Trial 10 finished with value: 0.6355711720283248 and parameters: {'max_len': 128, 'batch_size': 32, 'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.00021209814266304062, 'weight_decay': 0.0462251646842735, 'n_epochs': 3, 'pred_threshold': 0.5153456050569493, 'pos_weight': None, 'dropout': 0.12599288628717617}. Best is trial 4 with value: 0.833539184945753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5199263548409497\n",
      "Validation loss decreased (0.648964 --> 0.519926).\n",
      "F1 Score (Macro) = 0.6355711720283248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamw.AdamW'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.3458575010299683\n",
      "Validation Loss: 0.3449640896703516\n",
      "Validation loss decreased (inf --> 0.344964).\n",
      "Epoch: 2, batch_id: 0, Training Loss:  0.35398709774017334\n",
      "Validation Loss: 0.25309992049421587\n",
      "Validation loss decreased (0.344964 --> 0.253100).\n",
      "Epoch: 3, batch_id: 0, Training Loss:  0.08999602496623993\n",
      "Validation Loss: 0.2660609590155738\n",
      "Epoch: 4, batch_id: 0, Training Loss:  0.04650454223155975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 20:53:08,955] Trial 11 finished with value: 0.7836391333784699 and parameters: {'max_len': 128, 'batch_size': 64, 'optimizer': <class 'torch.optim.adamw.AdamW'>, 'lr': 2.0445182678867352e-05, 'weight_decay': 0.06518943036887243, 'n_epochs': 4, 'pred_threshold': 0.4004532515094353, 'pos_weight': None, 'dropout': 0.023369933788047866}. Best is trial 4 with value: 0.833539184945753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2552054151892662\n",
      "F1 Score (Macro) = 0.7836391333784699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamw.AdamW'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.4170558452606201\n",
      "Validation Loss: 0.2686879070741789\n",
      "Validation loss decreased (inf --> 0.268688).\n",
      "Epoch: 2, batch_id: 0, Training Loss:  0.22715406119823456\n",
      "Validation Loss: 0.25259698395218166\n",
      "Validation loss decreased (0.268688 --> 0.252597).\n",
      "Epoch: 3, batch_id: 0, Training Loss:  0.06161312013864517\n",
      "Validation Loss: 0.30400405717747553\n",
      "Epoch: 4, batch_id: 0, Training Loss:  0.07696433365345001\n",
      "Validation Loss: 0.303014085228954\n",
      "Epoch: 5, batch_id: 0, Training Loss:  0.13795286417007446\n",
      "Validation Loss: 0.3290892307247434\n",
      "Epoch: 6, batch_id: 0, Training Loss:  0.021063290536403656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 20:55:15,138] Trial 12 finished with value: 0.8323950846001721 and parameters: {'max_len': 128, 'batch_size': 64, 'optimizer': <class 'torch.optim.adamw.AdamW'>, 'lr': 5.7718418744101004e-05, 'weight_decay': 0.05830934887771915, 'n_epochs': 6, 'pred_threshold': 0.5138626116959413, 'pos_weight': None, 'dropout': 0.004188929109411509}. Best is trial 4 with value: 0.833539184945753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3347216940351895\n",
      "F1 Score (Macro) = 0.8323950846001721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamw.AdamW'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.4697681665420532\n",
      "Validation Loss: 0.3248633103711265\n",
      "Validation loss decreased (inf --> 0.324863).\n",
      "Epoch: 2, batch_id: 0, Training Loss:  0.32743126153945923\n",
      "Validation Loss: 0.2826417141727039\n",
      "Validation loss decreased (0.324863 --> 0.282642).\n",
      "Epoch: 3, batch_id: 0, Training Loss:  0.12598678469657898\n",
      "Validation Loss: 0.2560515031218529\n",
      "Validation loss decreased (0.282642 --> 0.256052).\n",
      "Epoch: 4, batch_id: 0, Training Loss:  0.07309100031852722\n",
      "Validation Loss: 0.32126688744340626\n",
      "Epoch: 5, batch_id: 0, Training Loss:  0.025450151413679123\n",
      "Validation Loss: 0.405750361936433\n",
      "Epoch: 6, batch_id: 0, Training Loss:  0.03928804397583008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 20:57:21,492] Trial 13 finished with value: 0.8320828376944298 and parameters: {'max_len': 128, 'batch_size': 64, 'optimizer': <class 'torch.optim.adamw.AdamW'>, 'lr': 8.246217019939104e-05, 'weight_decay': 0.0533609679919179, 'n_epochs': 6, 'pred_threshold': 0.5206633142342406, 'pos_weight': None, 'dropout': 0.08850673364241787}. Best is trial 4 with value: 0.833539184945753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.40926848884139744\n",
      "F1 Score (Macro) = 0.8320828376944298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamw.AdamW'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.5233230590820312\n",
      "Validation Loss: 0.37843193113803864\n",
      "Validation loss decreased (inf --> 0.378432).\n",
      "Epoch: 2, batch_id: 0, Training Loss:  0.35721126198768616\n",
      "Validation Loss: 0.3192745330078261\n",
      "Validation loss decreased (0.378432 --> 0.319275).\n",
      "Epoch: 3, batch_id: 0, Training Loss:  0.1652277112007141\n",
      "Validation Loss: 0.33814194425940514\n",
      "Epoch: 4, batch_id: 0, Training Loss:  0.0935547947883606\n",
      "Validation Loss: 0.35298502338784077\n",
      "Epoch: 5, batch_id: 0, Training Loss:  0.06210114061832428\n",
      "Validation Loss: 0.3938551981534277\n",
      "Epoch: 6, batch_id: 0, Training Loss:  0.07515771687030792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 20:59:27,604] Trial 14 finished with value: 0.7950210767859887 and parameters: {'max_len': 128, 'batch_size': 64, 'optimizer': <class 'torch.optim.adamw.AdamW'>, 'lr': 7.150902172798073e-05, 'weight_decay': 0.08069232465961731, 'n_epochs': 6, 'pred_threshold': 0.5022896450695422, 'pos_weight': (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147), 'dropout': 0.09735771382762085}. Best is trial 4 with value: 0.833539184945753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.41349683701992035\n",
      "F1 Score (Macro) = 0.7950210767859887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamw.AdamW'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.455475926399231\n",
      "Validation Loss: 0.40597689683948246\n",
      "Validation loss decreased (inf --> 0.405977).\n",
      "Epoch: 2, batch_id: 0, Training Loss:  0.3853582739830017\n",
      "Validation Loss: 0.35076800840241573\n",
      "Validation loss decreased (0.405977 --> 0.350768).\n",
      "Epoch: 3, batch_id: 0, Training Loss:  0.13234567642211914\n",
      "Validation Loss: 0.3500069880059787\n",
      "Validation loss decreased (0.350768 --> 0.350007).\n",
      "Epoch: 4, batch_id: 0, Training Loss:  0.09111130237579346\n",
      "Validation Loss: 0.38343965262174606\n",
      "Epoch: 5, batch_id: 0, Training Loss:  0.12304380536079407\n",
      "Validation Loss: 0.6042602381535939\n",
      "Epoch: 6, batch_id: 0, Training Loss:  0.19505059719085693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 21:01:33,616] Trial 15 finished with value: 0.7972744578545176 and parameters: {'max_len': 128, 'batch_size': 64, 'optimizer': <class 'torch.optim.adamw.AdamW'>, 'lr': 0.0001598442877977317, 'weight_decay': 0.030358454855414874, 'n_epochs': 6, 'pred_threshold': 0.5283463270807652, 'pos_weight': None, 'dropout': 0.1890491129951202}. Best is trial 4 with value: 0.833539184945753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4437131317598479\n",
      "F1 Score (Macro) = 0.7972744578545176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamw.AdamW'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.451263666152954\n",
      "Validation Loss: 0.3311465489012855\n",
      "Validation loss decreased (inf --> 0.331147).\n",
      "Epoch: 2, batch_id: 0, Training Loss:  0.2548491358757019\n",
      "Validation Loss: 0.34658022171684677\n",
      "Epoch: 3, batch_id: 0, Training Loss:  0.10660652071237564\n",
      "Validation Loss: 0.3331595765692847\n",
      "Epoch: 4, batch_id: 0, Training Loss:  0.06459116190671921\n",
      "Validation Loss: 0.28294359307203976\n",
      "Validation loss decreased (0.331147 --> 0.282944).\n",
      "Epoch: 5, batch_id: 0, Training Loss:  0.0867721289396286\n",
      "Validation Loss: 0.4959621663604464\n",
      "Epoch: 6, batch_id: 0, Training Loss:  0.05628225952386856\n",
      "Validation Loss: 0.40468574155654224\n",
      "Epoch: 7, batch_id: 0, Training Loss:  0.05415549501776695\n",
      "Validation Loss: 0.5116495734878949\n",
      "Epoch: 8, batch_id: 0, Training Loss:  0.004344717133790255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 21:04:21,355] Trial 16 finished with value: 0.8044816330206688 and parameters: {'max_len': 128, 'batch_size': 64, 'optimizer': <class 'torch.optim.adamw.AdamW'>, 'lr': 0.00014509983766118782, 'weight_decay': 0.054676034888416256, 'n_epochs': 8, 'pred_threshold': 0.552526366807257, 'pos_weight': None, 'dropout': 0.284682856831649}. Best is trial 4 with value: 0.833539184945753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.45800994975226267\n",
      "F1 Score (Macro) = 0.8044816330206688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamw.AdamW'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.5468353033065796\n",
      "Validation Loss: 0.4048457933323724\n",
      "Validation loss decreased (inf --> 0.404846).\n",
      "Epoch: 2, batch_id: 0, Training Loss:  0.3987513780593872\n",
      "Validation Loss: 0.3603315544979913\n",
      "Validation loss decreased (0.404846 --> 0.360332).\n",
      "Epoch: 3, batch_id: 0, Training Loss:  0.19617778062820435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 21:05:24,953] Trial 17 finished with value: 0.7745495906575453 and parameters: {'max_len': 128, 'batch_size': 64, 'optimizer': <class 'torch.optim.adamw.AdamW'>, 'lr': 4.678820053593776e-05, 'weight_decay': 0.08418466661145904, 'n_epochs': 3, 'pred_threshold': 0.48046983476444466, 'pos_weight': (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147), 'dropout': 0.07557234190646156}. Best is trial 4 with value: 0.833539184945753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3560596640620913\n",
      "Validation loss decreased (0.360332 --> 0.356060).\n",
      "F1 Score (Macro) = 0.7745495906575453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamw.AdamW'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.33132004737854\n",
      "Validation Loss: 0.35147449760525307\n",
      "Validation loss decreased (inf --> 0.351474).\n",
      "Epoch: 2, batch_id: 0, Training Loss:  0.43396323919296265\n",
      "Validation Loss: 0.34638942778110504\n",
      "Validation loss decreased (0.351474 --> 0.346389).\n",
      "Epoch: 3, batch_id: 0, Training Loss:  0.11742929369211197\n",
      "Validation Loss: 0.36470598589490955\n",
      "Epoch: 4, batch_id: 0, Training Loss:  0.21328313648700714\n",
      "Validation Loss: 0.37190575069851345\n",
      "Epoch: 5, batch_id: 0, Training Loss:  0.3442346453666687\n",
      "Validation Loss: 0.3811073805446978\n",
      "Epoch: 6, batch_id: 0, Training Loss:  0.1699095219373703\n",
      "Validation Loss: 0.37231286090833177\n",
      "Epoch: 7, batch_id: 0, Training Loss:  0.2327701598405838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 21:07:59,853] Trial 18 finished with value: 0.6036807931636783 and parameters: {'max_len': 128, 'batch_size': 32, 'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 5.891322718210161e-05, 'weight_decay': 0.06911409460509066, 'n_epochs': 7, 'pred_threshold': 0.43491764886374135, 'pos_weight': None, 'dropout': 0.140776673790016}. Best is trial 4 with value: 0.833539184945753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5315450772091196\n",
      "F1 Score (Macro) = 0.6036807931636783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamw.AdamW'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-b8f46cb1-447b-406b-bf59-ea19b9c278a8/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.4997118711471558\n",
      "Validation Loss: 0.40812833181449343\n",
      "Validation loss decreased (inf --> 0.408128).\n",
      "Epoch: 2, batch_id: 0, Training Loss:  0.33915501832962036\n",
      "Validation Loss: 0.41313333277191433\n",
      "Epoch: 3, batch_id: 0, Training Loss:  0.2685280442237854\n",
      "Validation Loss: 0.44563062914780205\n",
      "Epoch: 4, batch_id: 0, Training Loss:  0.16497300565242767\n",
      "Validation Loss: 0.34760605330978117\n",
      "Validation loss decreased (0.408128 --> 0.347606).\n",
      "Epoch: 5, batch_id: 0, Training Loss:  0.2302575707435608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-26 21:09:45,032] Trial 19 finished with value: 0.8213997690786201 and parameters: {'max_len': 128, 'batch_size': 64, 'optimizer': <class 'torch.optim.adamw.AdamW'>, 'lr': 0.0001168028361289839, 'weight_decay': 0.08659730108809818, 'n_epochs': 5, 'pred_threshold': 0.5536430298088009, 'pos_weight': (2.242021276595745, 2.1782945736434107, 1.0459057071960298, 0.46755407653910147), 'dropout': 0.052972590932764754}. Best is trial 4 with value: 0.833539184945753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3713875040411949\n",
      "F1 Score (Macro) = 0.8213997690786201\n",
      "Time elapsed: 2173.090669155121\n"
     ]
    }
   ],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Fine tune a pre-trained BERT model, adjusted to learn our labels\n",
    "\n",
    "    Contains a dropout layer that aims to minimize overfitting and a final linear layer that inputs\n",
    "    768 dimension features from BERT and returns number of target features\n",
    "\n",
    "    Forward method is used to feed input to BERT\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bert_model_name: pre-trained model to use for fine-tuning\n",
    "    dropout: float value to minimize overfitting\n",
    "    classes_len: number of target labels\n",
    "    \"\"\"\n",
    "    def __init__(self, dropout, classes_len):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "        self.l2 = torch.nn.Dropout(dropout)\n",
    "        self.l3 = torch.nn.Linear(768, 4)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict = False)\n",
    "        output_2 = self.l2(output_1)\n",
    "        output = self.l3(output_2)\n",
    "        return output\n",
    "\n",
    "def prepare_loaders(train_dataset, valid_dataset, max_len, batch_size, num_workers):\n",
    "    \"\"\"\n",
    "    Utility function that uses torch.utils.data.DataLoader class to create iterable over a dataset\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Calls ConsortDataSet class to tokenize and encode text. See docstring for more info\n",
    "        train_dataset\n",
    "        valid_dataset\n",
    "        tokenizer\n",
    "        max_len\n",
    "\n",
    "    batch_size: int for how many samples per batch to load\n",
    "    num_workers: int for how many subprocesses to use for data loading\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    training_loader: iterable training dataset\n",
    "    validation_loader: iterable validation dataset\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    training_set = SoftwareDataset(train_dataset, max_len)\n",
    "\n",
    "    training_loader = DataLoader(\n",
    "        training_set,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True,\n",
    "        num_workers = num_workers)\n",
    "\n",
    "    validation_set = SoftwareDataset(valid_dataset, max_len)\n",
    "\n",
    "    validation_loader = DataLoader(\n",
    "        validation_set,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True,\n",
    "        num_workers = num_workers)\n",
    "\n",
    "    return training_loader, validation_loader\n",
    "\n",
    "def train(model, training_loader, optimizer, epoch, pos_weight, device):\n",
    "    \"\"\"\n",
    "    For each batch of training data:\n",
    "        1. Unpack batch from training loader\n",
    "        2. Isolate batch ids, mask, token_type_ids and target values\n",
    "        3. Perform a forward pass over data\n",
    "        4. Clear previously calculated gradients\n",
    "        5. Calculate loss\n",
    "        6. Clear gradients\n",
    "        7. Perform backward pass to calculate gradients\n",
    "        8. Update parameters and take step using computed gradient\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    model: model class object to be trained\n",
    "    training_loader: iterable dataset used to train\n",
    "    optimizer: optimizer to be used to update parameters\n",
    "    epoch: maximum number of epochs to be trained on\n",
    "    pos_weight: class weighting to be used in loss function\n",
    "    \"\"\"\n",
    "\n",
    "    model.train() #set model to training mode\n",
    "    for batch_idx, data in enumerate(training_loader):   #1\n",
    "        # print('epoch', batch_idx)\n",
    "        ids = data['ids'].to(device, dtype = torch.long)    #2\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids) #3\n",
    "\n",
    "        optimizer.zero_grad()   #4\n",
    "        # loss = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)(outputs, targets)   #5\n",
    "        loss = torch.nn.CrossEntropyLoss(weight=pos_weight)(outputs, targets)\n",
    "        optimizer.zero_grad()  #6\n",
    "        loss.backward()  #7\n",
    "        optimizer.step()  #8\n",
    "\n",
    "        if batch_idx%5000==0:\n",
    "           print(f'Epoch: {epoch}, batch_id: {batch_idx}, Training Loss:  {loss.item()}')\n",
    "\n",
    "\n",
    "def test(model, validation_loader, valid_loss_input, pos_weight, device):\n",
    "    \"\"\"\n",
    "    For each batch of testing data:\n",
    "        1.Tell pytorch not to both constructing the compute graph during forward pass since only needed for backprop\n",
    "        2. Unpack batch from validation loader\n",
    "        3. Isolate batch ids, mask, token_type_ids and target values\n",
    "        4. Calculate predictions\n",
    "        5. Calculate loss\n",
    "        6. Accumulate validation loss\n",
    "        7/8. Move labels and predictions to CPU and append to lists\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    model: trained model to validate\n",
    "    validation_loader: iterable dataset used to validate\n",
    "    valid_loss_input: initial input loss value\n",
    "    pos_weight: class weighting to be used in loss function\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    val_targets: list of true validation targets\n",
    "    val_outputs: list of predicated validation targets\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval() #put model in evaluation mode\n",
    "    valid_loss = 0\n",
    "    valid_loss_min = valid_loss_input\n",
    "    val_targets = []\n",
    "    val_outputs = []\n",
    "\n",
    "    with torch.no_grad(): #1\n",
    "      for batch_idx, data in enumerate(validation_loader, 0):   #2\n",
    "            ids = data['ids'].to(device, dtype = torch.long)    #3\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)   #4\n",
    "\n",
    "            # loss = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)(outputs, targets) #5\n",
    "            loss = torch.nn.CrossEntropyLoss(weight=pos_weight)(outputs, targets)\n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))  #6\n",
    "            val_targets.extend(targets.cpu().detach().numpy().tolist())  #7\n",
    "            val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())   #8\n",
    "\n",
    "\n",
    "\n",
    "    print(f'Validation Loss: {valid_loss}')\n",
    "\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).'.format(valid_loss_min,valid_loss))\n",
    "        valid_loss_min = valid_loss\n",
    "\n",
    "    return val_targets, val_outputs, valid_loss_min\n",
    "\n",
    "def predict_and_score(val_targets, val_outputs, pred_threshold):\n",
    "    \"\"\"\n",
    "    Calculate accuracy, f1_macro, and f1_micro using sklearn.metrics library\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    val_targets: list of true validation targets\n",
    "    val_outputs: list of predicated validation targets\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    f1_score_macro: skelarn.metrics.f1_score with average='macro'\n",
    "    \"\"\"\n",
    "\n",
    "    val_preds = (np.array(val_outputs) > pred_threshold).astype(int)\n",
    "\n",
    "    f1_score_macro = f1_score(val_targets, val_preds, average='macro')\n",
    "\n",
    "    return f1_score_macro\n",
    "\n",
    "def pos_weights(df, classes_len):\n",
    "    \"\"\"\n",
    "    Calculate weights for each class. Returns np.tobytes() because torch tensor isn't\n",
    "    compatibilite with Optuna.trial.Trial.suggest_categorical()\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    df: pd.DataFrame\n",
    "    classes_len: int number of classes in dataset\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "     \n",
    "    torch tensor of length number of classes\n",
    "    \"\"\"\n",
    "    pos_counts = np.array(df[\"vectorized_labels\"].values.tolist()).sum(axis=0)\n",
    "    n_samples = len(df)\n",
    "    \n",
    "    weights = n_samples / (classes_len * pos_counts)\n",
    "\n",
    "    return tuple(weights)\n",
    "\n",
    "\n",
    "def run(trial, train_dataset, valid_dataset):\n",
    "    \"\"\"\n",
    "    Train BERT model for fine tuning on data\n",
    "\n",
    "    -Uses Optuna to define and train hyperparameters found in CONFIG\n",
    "    -Loads training and validation loaders\n",
    "    -Trains model\n",
    "    -Returns macro F1 score that Optuna uses to maximize and tune parameters\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    train_dataset: pd.DataFrame that contains training samples\n",
    "    valid_dataset: pd.DataFrame that contains validation samples\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    f1_score_macro: objective measure\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    CONFIG = {\n",
    "        'seed': 42,\n",
    "        'max_len': trial.suggest_categorical('max_len', [128]),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [32, 64]),\n",
    "        'num_workers': 0,\n",
    "        'classes_len': len(CLASSES),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', [torch.optim.Adam, torch.optim.AdamW]),\n",
    "        'lr': trial.suggest_float('lr', 1e-5, 4e-4),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 0, 0.1),\n",
    "        'n_epochs': trial.suggest_int('n_epochs', 1, 8),\n",
    "        'pred_threshold': trial.suggest_float('pred_threshold', 0.3, 0.6),\n",
    "        'pos_weight': trial.suggest_categorical('pos_weight', [None, pos_weights(train_dataset, len(CLASSES))]),\n",
    "        'dropout': trial.suggest_float('dropout', 0.0, 0.6),\n",
    "        'device': \"cuda\",\n",
    "        }\n",
    "\n",
    "    device = torch.device(CONFIG['device'])\n",
    "    model = BERTClass(CONFIG['dropout'], CONFIG['classes_len'])\n",
    "    model.to(device)\n",
    "\n",
    "    if CONFIG['pos_weight'] != None:\n",
    "        pos_weight = torch.tensor(CONFIG['pos_weight'],dtype=torch.float).to(device, dtype = torch.float)\n",
    "    else:\n",
    "        pos_weight = CONFIG['pos_weight']\n",
    "\n",
    "    torch.manual_seed(CONFIG['seed'])\n",
    "\n",
    "    training_loader, validation_loader = prepare_loaders(train_dataset, valid_dataset, CONFIG['max_len'], CONFIG['batch_size'], CONFIG['num_workers'])\n",
    "\n",
    "    optimizer = CONFIG['optimizer'](params =  model.parameters(), lr=CONFIG['lr'], weight_decay=CONFIG['weight_decay'])\n",
    "\n",
    "    valid_loss_input = np.Inf\n",
    "\n",
    "    for epoch in range(1, CONFIG['n_epochs']+1):\n",
    "\n",
    "        train(model, training_loader, optimizer, epoch, pos_weight, device)\n",
    "        val_targets, val_outputs, valid_loss_min = test(model, validation_loader, valid_loss_input, pos_weight, device)\n",
    "        valid_loss_input = valid_loss_min\n",
    "\n",
    "    f1_score_macro = predict_and_score(val_targets, val_outputs, CONFIG['pred_threshold'])\n",
    "\n",
    "    print(f\"F1 Score (Macro) = {f1_score_macro}\")\n",
    "\n",
    "    return f1_score_macro\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(n_startup_trials=5)\n",
    "    study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "    start = time.time()\n",
    "    study.optimize(lambda trial: run(trial, train_dataset, valid_dataset), n_trials=20)\n",
    "    end = time.time()\n",
    "    print('Time elapsed:', end - start)\n",
    "    joblib.dump(study, f\"{OUTPUT_PATH}/optuna_software_context_mentions.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7dca1bc-f8d4-4d9a-adff-9119b32c977f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "optuna_scibert = joblib.load(f\"{OUTPUT_PATH}/optuna_software_mentions.pkl\")\n",
    "best_params = optuna_scibert.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cada0771-ce9d-44fb-9b59-6533150b2b66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def run_best(train_dataset, valid_dataset, best_params):\n",
    "    \"\"\"\n",
    "    Train BERT model for fine tuning on CONSORT data\n",
    "    \n",
    "    -Uses Optuna to define and train hyperparameters found in CONFIG\n",
    "    -Loads training and validation loaders\n",
    "    -Trains model\n",
    "    -Returns macro F1 score that Optuna uses to maximize and tune parameters\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    train_dataset: pd.DataFrame that contains training samples\n",
    "    valid_dataset: pd.DataFrame that contains validation samples\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    f1_score_macro: objective measure\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    CONFIG = {\n",
    "        'seed': 42,\n",
    "        'max_len': 'default',\n",
    "        'batch_size': 'default',\n",
    "        'num_workers': 0,\n",
    "        'classes_len': len(CLASSES),\n",
    "        'optimizer': 'default',\n",
    "        'num_warmup_steps':'default',\n",
    "        'lr': 'default',\n",
    "        'weight_decay': 'default',\n",
    "        'n_epochs': 'default',\n",
    "        'pred_threshold': 'default',\n",
    "        'pos_weight': 'default',\n",
    "        'dropout': 'default',\n",
    "        'device': \"cuda\"}\n",
    "\n",
    "    CONFIG.update(best_params)\n",
    "    joblib.dump(CONFIG, f\"{OUTPUT_PATH}/config_scibert.pkl\")\n",
    "    \n",
    "    model = BERTClass(CONFIG['dropout'], CONFIG['classes_len'])\n",
    "    device = torch.device(CONFIG['device'])\n",
    "    model.to(device)\n",
    "    \n",
    "    torch.manual_seed(CONFIG['seed'])\n",
    "\n",
    "    if CONFIG['pos_weight'] != None:\n",
    "        pos_weight = torch.tensor(CONFIG['pos_weight'],dtype=torch.float).to(device, dtype = torch.float)\n",
    "    else:\n",
    "        pos_weight = CONFIG['pos_weight']\n",
    "    \n",
    "    training_loader, validation_loader = prepare_loaders(train_dataset, valid_dataset, CONFIG['max_len'], CONFIG['batch_size'], CONFIG['num_workers'])\n",
    "    \n",
    "    optimizer = CONFIG['optimizer'](params =  model.parameters(), lr=CONFIG['lr'], weight_decay=CONFIG['weight_decay'])\n",
    "    \n",
    "    valid_loss_input = np.Inf\n",
    "    \n",
    "    for epoch in range(1, CONFIG['n_epochs']+1):\n",
    "        \n",
    "        train(model, training_loader, optimizer, epoch, pos_weight, device)\n",
    "        val_targets, val_outputs, valid_loss_min = test(model, validation_loader, valid_loss_input, pos_weight, device)\n",
    "        valid_loss_input = valid_loss_min\n",
    "        \n",
    "    # micro_hamming_loss = predict_and_score(val_targets, val_outputs, CONFIG['pred_threshold'], CONFIG['classes_len'])\n",
    "    # print(f\"Hamming Loss (Micro) = {micro_hamming_loss}\")\n",
    "    f1_score_macro = predict_and_score(val_targets, val_outputs, CONFIG['pred_threshold'])\n",
    "\n",
    "    print(f\"F1 Score (Macro) = {f1_score_macro}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{OUTPUT_PATH}/SciBERT_software_intent.pt\")\n",
    "    val_preds = (np.array(val_outputs) > CONFIG['pred_threshold']).astype(int)\n",
    "    print(classification_report(val_targets, val_preds, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20981ced-c405-4404-aaae-d2e277b5ce4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 0, Training Loss:  1.6253738403320312\n",
      "Validation Loss: 0.3566967653376716\n",
      "Validation loss decreased (inf --> 0.356697).\n",
      "Epoch: 2, batch_id: 0, Training Loss:  0.3374609351158142\n",
      "Validation Loss: 0.3775885168995176\n",
      "Epoch: 3, batch_id: 0, Training Loss:  0.23997914791107178\n",
      "Validation Loss: 0.32245428647313795\n",
      "Validation loss decreased (0.356697 --> 0.322454).\n",
      "Epoch: 4, batch_id: 0, Training Loss:  0.07606830447912216\n",
      "Validation Loss: 0.3689432575234345\n",
      "Epoch: 5, batch_id: 0, Training Loss:  0.04355796426534653\n",
      "Validation Loss: 0.36896095212016783\n",
      "F1 Score (Macro) = 0.8098151346177715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     created       0.72      0.99      0.83        94\n",
      "     mention       0.51      0.92      0.66        96\n",
      "   unlabeled       0.70      1.00      0.82       202\n",
      "        used       0.91      0.95      0.93       451\n",
      "\n",
      "   micro avg       0.76      0.96      0.85       843\n",
      "   macro avg       0.71      0.96      0.81       843\n",
      "weighted avg       0.79      0.96      0.86       843\n",
      " samples avg       0.85      0.96      0.89       843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_best(train_dataset, valid_dataset, best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab79aaef-dc2c-481a-b6c7-e16c01e90a06",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab259f83-f8c3-4984-84e2-7a6cdef18067",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "evaluation_df = pd.read_csv('/Workspace/Users/k.moraw@epcc.ed.ac.uk/data/software_citation_intent_czi.csv')\n",
    "joss_df = pd.read_csv('/dbfs/FileStore/citation_intent/joss_creation.csv')\n",
    "joss_df = joss_df.rename(columns={'intent':'label'})\n",
    "joss_df = joss_df[['sentence', 'label']]\n",
    "joss_df['label'] = joss_df['label'].replace('creation', 'created')\n",
    "evaluation_df = evaluation_df[['text', 'Intent (creation, used, mention)']]\n",
    "evaluation_df = evaluation_df.rename(columns={'text':'sentence', 'Intent (creation, used, mention)':'label'})\n",
    "# evaluation_df['label'] = evaluation_df['label'].apply(lambda x: [x])\n",
    "combined_df = pd.concat([evaluation_df, joss_df]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c206333-7112-4da5-a8ef-7fee1f9c9392",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "used       344\n",
       "mention     30\n",
       "created     10\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3f24c74-3132-42a2-9d09-575a86385271",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config_path = f\"{OUTPUT_PATH}/config_scibert.pkl\"\n",
    "state_dict = f\"{OUTPUT_PATH}/SciBERT_software_intent.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "884d039c-a6b6-408a-831c-ef2f520aacb3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class EvaluationSoftwareDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset class that inherits from torch.utils.data.Dataset\n",
    "\n",
    "    Makes use of Hugging Face transformer encode_plus method to:\n",
    "        -Split sentence into tokens\n",
    "        -Add special [CLS] and [SEP] tokens\n",
    "        -Map tokens to IDs\n",
    "        -Pad/truncate sentences to max length\n",
    "        -Create attention masks\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    dataframe: pd.DataFrame used for model training, contains columns 'text' and vectorized labels 'target_list'\n",
    "    tokenizer: tokenizer from transformers library used to prepare inputs for model\n",
    "    max_len: maximum length (in number of tokens) for the inputs to model\n",
    "\n",
    "    Returns\n",
    "    _______\n",
    "\n",
    "    dict: Dictionary of encoded ids, mask, token_type_ids, and targets\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataframe, max_len):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "        self.data = dataframe\n",
    "        self.text = self.data.sentence\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self): # overrides __len__ so that len(dataset) returns size of dataset\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index): #override __getitem__ to support indexing\n",
    "        text = str(self.text[index])\n",
    "        text = ' '.join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens = True,\n",
    "            max_length = self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids = True,\n",
    "            truncation = True\n",
    "        )\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs['token_type_ids']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd6e283d-7847-4091-bab7-4790c0cce065",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def run_inference_and_score(valid_dataset):\n",
    "\n",
    "    CONFIG = joblib.load(config_path)\n",
    "    model = BERTClass(CONFIG['dropout'], CONFIG['classes_len'])\n",
    "\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.load_state_dict(torch.load(state_dict, map_location=torch.device('cuda')))\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(state_dict, map_location=torch.device('cpu')))\n",
    "        device = torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    validation_set = EvaluationSoftwareDataset(valid_dataset, CONFIG['max_len'])\n",
    "\n",
    "    validation_loader = DataLoader(\n",
    "        validation_set,\n",
    "        batch_size = CONFIG['batch_size'],\n",
    "        shuffle = False,\n",
    "        num_workers = 0)\n",
    "    \n",
    "    model.eval() #put model in evaluation mode\n",
    "    val_outputs = []\n",
    "\n",
    "    with torch.no_grad(): #1\n",
    "      for batch_idx, data in enumerate(validation_loader, 0):   #2\n",
    "            ids = data['ids'].to(device, dtype = torch.long)    #3\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, mask, token_type_ids)   #4\n",
    "\n",
    "            val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    \n",
    "    output_array = np.array(val_outputs)\n",
    "    val_preds = (output_array == output_array.max(axis=1, keepdims=1)).astype(int)\n",
    "    val_preds = mlb.inverse_transform(val_preds)\n",
    "    val_preds = [i[0] for i in val_preds]\n",
    "    \n",
    "\n",
    "    # print(classification_report(val_targets, val_preds, target_names=mlb.classes_))\n",
    "    return val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2be5341a-2b5e-47a1-9e4c-f332fd987aaa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predictions = run_inference_and_score(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f07bd57-dbd6-4e8e-b8d6-191bf3977557",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     created       0.00      0.00      0.00        10\n",
      "     mention       0.07      0.13      0.09        30\n",
      "   unlabeled       0.00      0.00      0.00         0\n",
      "        used       0.89      0.70      0.78       344\n",
      "\n",
      "    accuracy                           0.64       384\n",
      "   macro avg       0.24      0.21      0.22       384\n",
      "weighted avg       0.80      0.64      0.71       384\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(combined_df['label'].tolist(), predictions, target_names=mlb.classes_))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "multiclass_bert_classifier",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
